Обучает слабые модели последовательно, исправляя ошибки предыдущих.

Результатом градиентного бустинга является средневзвешенная сумма результатов моделей.

Отличие от Adaboost - это способ изменения весов (итеративный метод – градиентный метод) 

Обобщение адаптивного бустинга для дифференцируемых функций.

```Python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
data, target = load_breast_cancer(return_X_y=True)
modelClf = GradientBoostingClassifier(max_depth=2, n_estimators=150,
random_state=12, learning_rate=1)
X_train, X_valid, y_train, y_valid = train_test_split(data, target, test_size=0.3,
random_state=12)
modelClf.fit(X_train, y_train)
print(modelClf.score(X_valid, y_valid))
```