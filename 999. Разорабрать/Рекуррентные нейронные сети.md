#todo
# Понятие
Рекуррентные нейронные сети (RNN) — это класс нейронных сетей, которые хороши для моделирования последовательных данных, таких как [[Временный ряд|временные ряды]] или естественный язык.

RNN выполняет одну и ту же задачу для каждого элемента последовательности, выходное значение зависит от предыдущих вычислений

RNN - сети с памятью, учитывающие предшествующую информацию


![[Pasted image 20241115105215.png]]


Проблема традиционных нейронных сетей: не зависимость входов и выходов. Слова в предложении взаимосвязаны.

Последовательность – это данные, где соседние точки зависят друг от друга.

# Примеры последовательностей в данных

1. Видео
2. Аудио
3. Текст
4. Диалогии

# [[Задачи, решаемые RNN]]
# [[Архитектура реккурентной нейронной сети (RNN)]]

# Последовательности с вариантивными длинами как для входа, так и для вывода

![[Pasted image 20241115111541.png]]

![[Pasted image 20241115111548.png]]

![[Pasted image 20241115111553.png]]

![[Pasted image 20241115111558.png]]

![[Pasted image 20241115111619.png]]

![[Pasted image 20241115111623.png]]
# Алгоритм распространения ошибки сквозь время

Ошибка сети есть сумма ее ошибок для всех t
Общий градиент по переменной есть сумма ее градиентов для всех t

![[Pasted image 20241115111658.png]]

Трудности изучения долгосрочных зависимостей
# [[Глубокие архитектуры RNN]]

# [[Проблемы рекуррентными НС]]

# [[LSTM]]

# [[Управляемые рекуррентные блоки GRU (gated recurrent unit)]]

# [[RNN в Keras]]

# [[Двунаправленные рекуррентные сети]]

# [[Сверточные рекуррентные нейронные сети (CRNN)]]



