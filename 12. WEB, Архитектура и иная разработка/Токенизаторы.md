
**Токенизатор** (Tokenizer) *принимает поток символов* (stream of characters), *разбивает его* на *отдельные токены* (individual tokens) и *возвращает поток токенов*. Чаще всего токенами являются отдельные слова. 

*Процесс разбиения потока символов* на *токены* называется **токенизацией** (tokenization).

Именно *благодаря токенизации доступен полтотекстовый поиск*, ведь *каждый токен индексируется отдельно*.

Ранее было показано, как *токенизаторы встроенных анализаторов* разделяют текст на токены (термы).

*Токенизатор* также *отвечает за порядок термов* (порядок может меняться).

*Один анализатор имеет ровно один токенизатор*.



Помимо перечисленных ранее функций, *токенизаторы* также *задают* **тип токенов** (token type). 

*Простые токенизаторы* *разбиват текст* на *слова* и задают *тип* `word`. *Другие токенизаторы* могут задавать *типы* `<ALPHANUM>`, `<HANGUL>`, `<NUM>`.

*Виды токенизаторов*
* *Ориентированные на слова*.
* *Токенизаторы частичных слов*.
* *Токенизаторы структурированного текста*.

## Ориентированные на слова

**Ориентированные на слова токенизаторы** (Word oriented tokenizer) разбивают текст на отдельные токены, которые явяются словами. 

Задаваемый тип токенов: `word`.

## Токенизаторы частичных слов

**Токенизаторы частичных слов** (Partial word tokenizer) разбивают текст или слова на маленькие фрагменты для проверки на частичное совпадение слов.

### N-gram

### Edge n-gram

## Токенизаторы структурированного текста

**Токенизаторы структурированного текста** (Structured text tokenizer) обычно используются не для полнотекстового поиска, а для идентификаторов (`id`, `email`, `phone` и так далее).

