#todo 
1. Очистка и форматирование данных
2. Разведочный анализ данных
3. Конструирование и выбор признаков
4. Сравнение метрик нескольких моделей машинного обучения
5. Гиперпараметрическая настройка лучшей модели
6. Оценка лучшей модели на тестовом наборе данных
7. Интерпретирование результатов работы модели

![[Pasted image 20241114144329.png]]

# Описание задачи

## Датасет
Данные об энергоэффективности зданий в Нью-Йорке
## Цель
Построение модели, которая прогнозирует количество баллов Energy Star Score для конкретного здания, и интерпретирует результаты для поиска факторов, влияющих на итоговый балл.
## Задача
Регрессия

# 1. Очистка и форматирование данных

Отсутствующие значения Not Available => np.nan или удаление

Конвертирование типа данных Object => числовой

Удаление аномальных данных

Заполнение отсутствующих значений

Масштабирование признаков (нормализация)

![[Pasted image 20241114144447.png]]

# 2. Разведочный анализ данных

Вычисляется статистика и поиск в данных тенденции, аномалий, шаблонов или взаимосвязей.

Анализ распределения прогнозированного значения Energy Star Score

![[Pasted image 20241114144520.png]]

## Поиск взаимосвязей

![[Pasted image 20241114144539.png]]

## Диаграммы рассеивания

EUI (Energy Use Intensity, интенсивность использования энергии) — это количество энергии, потреблённой зданием, делённое на квадратный фут площади. Эта удельная величина используется для оценки энергоэффективности, и чем она меньше, тем лучше

![[Pasted image 20241114144625.png]]

## Парный график

Диаграмма рассеивания – верхний треугольник

Гистограмма – по диагонали

Диаграмма плотности – в нижнем треугольнике

Коэффициент корреляции Пирсона - мера интенсивности и направления линейной зависимости между двумя переменными. Значение +1 - идеальная линейная положительная зависимость, а -1 - идеальная линейная отрицательная зависимость.

![[Pasted image 20241114144704.png]]

# 3. Конструирование и выбор признаков

Процесс извлечения или создания новых признаков из сырых
данных.

Выбор признаков можно рассматривать как удалени «лишнего», чтобы осталось только самое важное.


•Применение к категориальным переменным (квартал и тип собственности) one-hot
кодирования.
•Взятие натурального логарифма от всех числовых переменных

## Выбор признаков

Коллинеарные признаки: удаление одного из признаков

Коэффициент корреляции больше 0.6 – признаки коллинеарны

![[Pasted image 20241114144804.png]]

# 4. Оценка и выбор модели МО

![[Pasted image 20241114144820.png]]

- [[линейная регрессия]]
- [[К-ближайших соседей (KNN)]]
- [[Случайный лес]]
- [[Градиентный бустинг]]
- [[Метод опорных векторов (SVM)]]

![[Pasted image 20241114144853.png]]

![[Pasted image 20241114144859.png]]

# 5. Гиперпараметрическая оптимизация модели

Гиперпараметры модели можно считать настройками алгоритма, которые задаются до начала его обучения. Например, гиперпараметром является количество деревьев в «случайном лесе», или количество соседей в методе k-ближайших соседей.

Параметры модели — то, что она узнаёт в ходе обучения, например, веса в линейной регрессии.

Гиперпараметры влияют на недообучение и переобучение

## Метод настройки гиперпараметров

[[Случайный поиск]] с [[Перекрестная проверка|перекрёстной проверкой]]

## Иллюстрация k-блочной перекрестной проверки

RandomizedSearchCV из Scikit-Learn

![[Pasted image 20241114145120.png]]

## Метод МО: Регрессионная модель на основе градиентного бустинга

Последовательное обучение слабых методов (дерево решений), учитывая ошибки, сделанные предшественниками

Гиперпараметры:
- loss: минимизация функции потерь;
- n_estimators: количество используемых слабых деревьев решений (decision trees);
- max_depth: максимальная глубина каждого дерева решений;
- min_samples_leaf: минимальное количество примеров, которые должны быть в «листовом» (leaf) узле дерева решений;
- min_samples_split: минимальное количество примеров, которые нужны для разделения узла дерева решений;
- max_features: максимальное количество признаков, которые используются для разделения узлов

![[Pasted image 20241114145314.png]]

# 6. Оценка с помощью текстовых данных

![[Pasted image 20241114145402.png]]

![[Pasted image 20241114145408.png]]

# 7. Интерпретация модели

1.Оценить важности признаков.
2.Визуализировать одно из деревьев решений.
3.Применить метод LIME — Local Interpretable Model-Agnostic Explainations, локальные интерпретируемые моделезависимые объяснения.

## Важности признаков

```Python
import pandas as pd
# model is the trained model
importances = model.feature_importances_
# train_features is the dataframe of training features
feature_list = list(train_features.columns)
# Extract the feature importances into a dataframe
feature_results = pd.DataFrame({'feature':
feature_list,'importance': importances})
# Show the top 10 most important
feature_results =
feature_results.sort_values('importance',ascending =
False).reset_index(drop=True)
feature_results.head(10)
```

![[Pasted image 20241114145509.png]]

## Визуализация дерева решений

```python
from sklearn import tree
# Extract a single tree (number 105)
single_tree = model.estimators_[105][0]
# Save the tree to a dot file
tree.export_graphviz(single_tree, out_file =
'images/tree.dot', feature_names = feature_list)
```

![[Pasted image 20241114145552.png]]

