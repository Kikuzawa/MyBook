- Высокая точность определения элементов из тренировочного набора данных
- Низкая предсказательная способность

**Регуляризация:** первопричиной переобучения является сложность модели (в смысле
количества ее параметров) ==> задача регуляризатора — понизить сложность модели,
сохранив количество ее параметров

**Искусственное расширение набора обучающих данных**

позволяет алгоритмам обучения строить менее сложные модели

# Примеры
- [[Аппроксимация многочлена]]
- [[Добавление регуляризаторов]]


# L2, L1 - регуляризация

**Наложение штрафов (penalising)** на веса с наибольшими значениями

**Коэффициент регуляризации** - коэффициент слишком мал, то эффект от резуляризации будет ничтожен, если же слишком велик - модель обнулит все веса

В регуляризации **L1 веса уменьшаюися на постоянное значение**, стремясь к 0

В регуляризации **L2 веса уменьшаются на значение, пропорциональное w**

