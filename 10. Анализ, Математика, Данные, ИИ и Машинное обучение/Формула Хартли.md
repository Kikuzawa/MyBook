[[Логарифм]]

Пусть *имеется* некоторый **алфавит `A`** **мощности `n`**, *символы* которого *используются* при *составлении сообщений*. 

**Формулой Хартли** называют *формулу*, по которой *вычисляется* **количество информации `I` в** некотором **сообщении длины `k`**, *составленном* из *символов алфавита* `A` *мощности* `n`:  
**`I = k • log2(n)`**.

Тогда **количество информации `i` в одном символе** *алфавита* `A` вычисляется по *формуле*:  
**`i = I ÷ k = log2(n)`**.

В качестве *единиц измерения* для `I` и `i` используются **биты**.

Из *последней формулы* и *свойств логарифма* *следует*, что *мощность алфавита* `A`:  
**`n = 2^i`**.

Поскольку *бит* является *минимальной* (*неделимой*) величиной, *количество информации округляется* до *целого числа*. Причём, происходит *округление вверх* (*к большему целому*, *математическое округление*), чтобы *не было потерь информации*:  
**`i = ⌈ log2(n) ⌉`**, **`I = k • i`**.

Например, в *английским языке* `26` *букв*, то есть `52` *символа*, если *учитывать* и *строчные*, и *прописные буквы*. Возьмём *английский алфавит в качестве алфавита* `A`, тогда `|A| = n = 52` и *количество информации* в *одном символе алфавита* `A` *равно* `i = ⌈ log2(52) ⌉ = log2(64) = 6` *бит*. В таком случае, *любое сообщение длины* `k = 7`, *составленное* из *символов алфавита* `A`, *займёт* `I = k • i = 42` *бит*.

